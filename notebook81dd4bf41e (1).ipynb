{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-22T08:47:57.096816Z","iopub.execute_input":"2023-10-22T08:47:57.097483Z","iopub.status.idle":"2023-10-22T08:47:57.109368Z","shell.execute_reply.started":"2023-10-22T08:47:57.097449Z","shell.execute_reply":"2023-10-22T08:47:57.108053Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.200d.txt\n/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.50d.txt\n/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.100d.txt\n/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing,metrics,manifold\nfrom sklearn.manifold import TSNE\nfrom sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV,cross_val_predict\nfrom imblearn.over_sampling import ADASYN,SMOTE\nfrom imblearn.under_sampling import NearMiss\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nimport collections\nimport matplotlib.patches as mpatches\nfrom sklearn.metrics import accuracy_score\n%matplotlib inline\nfrom sklearn.preprocessing import RobustScaler\nimport xgboost\nfrom imblearn.metrics import classification_report_imbalanced\nfrom sklearn.metrics import classification_report,roc_auc_score,roc_curve,r2_score,recall_score,confusion_matrix,precision_recall_curve\nfrom collections import Counter\nfrom sklearn.model_selection import StratifiedKFold,KFold,StratifiedShuffleSplit\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nstop_words = stopwords.words('english')\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.decomposition import PCA, TruncatedSVD,SparsePCA\nfrom nltk.tokenize import word_tokenize\nfrom collections import defaultdict\nfrom collections import Counter\nimport seaborn as sns\nfrom wordcloud import WordCloud,STOPWORDS\nimport nltk\nfrom nltk.corpus import stopwords\nimport string\nfrom plotly import tools\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom xgboost import XGBClassifier as xg\nfrom lightgbm import LGBMClassifier as lg\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingClassifier,RandomForestClassifier,AdaBoostClassifier,BaggingClassifier,ExtraTreesClassifier","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:47:57.111505Z","iopub.execute_input":"2023-10-22T08:47:57.112411Z","iopub.status.idle":"2023-10-22T08:47:57.137555Z","shell.execute_reply.started":"2023-10-22T08:47:57.112356Z","shell.execute_reply":"2023-10-22T08:47:57.136052Z"},"trusted":true},"execution_count":65,"outputs":[{"output_type":"display_data","data":{"text/html":"        <script type=\"text/javascript\">\n        window.PlotlyConfig = {MathJaxConfig: 'local'};\n        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n        if (typeof require !== 'undefined') {\n        require.undef(\"plotly\");\n        requirejs.config({\n            paths: {\n                'plotly': ['https://cdn.plot.ly/plotly-2.24.1.min']\n            }\n        });\n        require(['plotly'], function(Plotly) {\n            window._Plotly = Plotly;\n        });\n        }\n        </script>\n        "},"metadata":{}}]},{"cell_type":"code","source":"import subprocess\nfrom nltk.corpus import wordnet\n\ntry:\n    nltk.data.find('wordnet.zip')\nexcept:\n    nltk.download('wordnet', download_dir='/kaggle/working/')\n    command = \"unzip /kaggle/working/corpora/wordnet.zip -d /kaggle/working/corpora\"\n    subprocess.run(command.split())\n    nltk.data.path.append('/kaggle/working/')\n    \nnltk.download('wordnet')\nnltk.download('stopwords')\nnltk.download('punkt')","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2023-10-22T08:47:57.139185Z","iopub.execute_input":"2023-10-22T08:47:57.139599Z","iopub.status.idle":"2023-10-22T08:47:57.188918Z","shell.execute_reply.started":"2023-10-22T08:47:57.139513Z","shell.execute_reply":"2023-10-22T08:47:57.187722Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"[nltk_data] Downloading package wordnet to /kaggle/working/...\n[nltk_data]   Package wordnet is already up-to-date!\nArchive:  /kaggle/working/corpora/wordnet.zip\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"replace /kaggle/working/corpora/wordnet/lexnames? [y]es, [n]o, [A]ll, [N]one, [r]ename:  NULL\n(EOF or read error, treating as \"[N]one\" ...)\n","output_type":"stream"},{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"data=pd.read_csv(r\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:47:57.191194Z","iopub.execute_input":"2023-10-22T08:47:57.191614Z","iopub.status.idle":"2023-10-22T08:47:57.926462Z","shell.execute_reply.started":"2023-10-22T08:47:57.191584Z","shell.execute_reply":"2023-10-22T08:47:57.925323Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment\n0  One of the other reviewers has mentioned that ...  positive\n1  A wonderful little production. <br /><br />The...  positive\n2  I thought this was a wonderful way to spend ti...  positive\n3  Basically there's a family where a little boy ...  negative\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df=data[:1000]","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:47:57.927667Z","iopub.execute_input":"2023-10-22T08:47:57.928035Z","iopub.status.idle":"2023-10-22T08:47:57.933303Z","shell.execute_reply.started":"2023-10-22T08:47:57.928004Z","shell.execute_reply":"2023-10-22T08:47:57.932522Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"%%time\nle=preprocessing.LabelEncoder()\ndf_le=le.fit_transform(df.sentiment)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:47:57.934355Z","iopub.execute_input":"2023-10-22T08:47:57.935095Z","iopub.status.idle":"2023-10-22T08:47:57.950141Z","shell.execute_reply.started":"2023-10-22T08:47:57.935051Z","shell.execute_reply":"2023-10-22T08:47:57.948779Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"CPU times: user 866 µs, sys: 0 ns, total: 866 µs\nWall time: 885 µs\n","output_type":"stream"}]},{"cell_type":"code","source":"df['Binry']=df_le","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:47:57.951792Z","iopub.execute_input":"2023-10-22T08:47:57.953041Z","iopub.status.idle":"2023-10-22T08:47:57.963631Z","shell.execute_reply.started":"2023-10-22T08:47:57.953004Z","shell.execute_reply":"2023-10-22T08:47:57.962152Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_32/2372769580.py:1: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:47:57.967189Z","iopub.execute_input":"2023-10-22T08:47:57.968370Z","iopub.status.idle":"2023-10-22T08:47:57.981416Z","shell.execute_reply.started":"2023-10-22T08:47:57.968334Z","shell.execute_reply":"2023-10-22T08:47:57.980238Z"},"trusted":true},"execution_count":71,"outputs":[{"execution_count":71,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment  Binry\n0  One of the other reviewers has mentioned that ...  positive      1\n1  A wonderful little production. <br /><br />The...  positive      1\n2  I thought this was a wonderful way to spend ti...  positive      1\n3  Basically there's a family where a little boy ...  negative      0\n4  Petter Mattei's \"Love in the Time of Money\" is...  positive      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>Binry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>One of the other reviewers has mentioned that ...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>I thought this was a wonderful way to spend ti...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Basically there's a family where a little boy ...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"print(df.shape)\nprint(data.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:47:57.982809Z","iopub.execute_input":"2023-10-22T08:47:57.983141Z","iopub.status.idle":"2023-10-22T08:47:57.994880Z","shell.execute_reply.started":"2023-10-22T08:47:57.983114Z","shell.execute_reply":"2023-10-22T08:47:57.993540Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"(1000, 3)\n(50000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nimport string\npunctuations = string.punctuation\nimport re\ndef preprocessing(text):\n    var = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n    var = re.sub(r'^b\\s+', '', text)\n    var=var.lower()\n    var=var.split()\n    \n    punct_tag=re.compile(r'[^\\w\\s]')\n    var=punct_tag.sub(r'',text)\n    \n    html_tag=re.compile(r'<.*?>')\n    var=html_tag.sub(r'',text)\n    \n    emoji_clean= re.compile(\"[\"\n                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                           u\"\\U00002702-\\U000027B0\"\n                           u\"\\U000024C2-\\U0001F251\"\n                           \"]+\", flags=re.UNICODE)\n    var=emoji_clean.sub(r'',text)\n    \n    url_clean= re.compile(r\"https://\\S+|www\\.\\S+\")\n    var=url_clean.sub(r'',text)\n    \n    lemmatizer=WordNetLemmatizer()\n    var = [lemmatizer.lemmatize(word) for word in var if not word in set(stopwords.words('english'))and word not in punctuations ]\n    var=' '.join(var)\n    return var\ndef preprocess_text(text):\n    \n    var = re.sub(\"[^a-zA-Z0-9]\", \" \", text)\n    var = re.sub(r'^b\\s+', '', text)\n    var=re.sub(r'<.*?>','',text)\n    var=var.lower()\n    var=var.split()\n    lemmatizer=WordNetLemmatizer()\n    var = [lemmatizer.lemmatize(word) for word in var if not word in set(stopwords.words('english'))and word not in punctuations ]\n    var=' '.join(var)\n    return var","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:47:57.996480Z","iopub.execute_input":"2023-10-22T08:47:57.997221Z","iopub.status.idle":"2023-10-22T08:47:58.016943Z","shell.execute_reply.started":"2023-10-22T08:47:57.997185Z","shell.execute_reply":"2023-10-22T08:47:58.015724Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"CPU times: user 24 µs, sys: 0 ns, total: 24 µs\nWall time: 30.8 µs\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\ndf.review=df.review.apply(preprocess_text)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:47:58.018383Z","iopub.execute_input":"2023-10-22T08:47:58.018747Z","iopub.status.idle":"2023-10-22T08:48:33.065818Z","shell.execute_reply.started":"2023-10-22T08:47:58.018694Z","shell.execute_reply":"2023-10-22T08:48:33.064692Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"CPU times: user 31.1 s, sys: 3.92 s, total: 35 s\nWall time: 35 s\n","output_type":"stream"},{"name":"stderr","text":"<timed exec>:1: SettingWithCopyWarning:\n\n\nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n\n","output_type":"stream"}]},{"cell_type":"code","source":"def tfidf(data):\n    tfidfv = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), lowercase=True, max_features=150000)\n    fit_data_tfidf=tfidfv.fit_transform(data)\n    return fit_data_tfidf","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:48:33.067091Z","iopub.execute_input":"2023-10-22T08:48:33.067437Z","iopub.status.idle":"2023-10-22T08:48:33.073759Z","shell.execute_reply.started":"2023-10-22T08:48:33.067406Z","shell.execute_reply":"2023-10-22T08:48:33.072977Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nfrom keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.layers import LSTM, Dense,Flatten,Conv2D,Conv1D,GlobalMaxPooling1D,GlobalMaxPool1D\nfrom keras.optimizers import Adam\nimport numpy as np  \nimport pandas as pd \nimport keras.backend as k\nfrom keras.utils import pad_sequences\nfrom tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional,GRU\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.utils import to_categorical\nfrom keras.utils.vis_utils import plot_model","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:48:33.074963Z","iopub.execute_input":"2023-10-22T08:48:33.075435Z","iopub.status.idle":"2023-10-22T08:48:33.090057Z","shell.execute_reply.started":"2023-10-22T08:48:33.075408Z","shell.execute_reply":"2023-10-22T08:48:33.088760Z"},"trusted":true},"execution_count":76,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:48:33.091394Z","iopub.execute_input":"2023-10-22T08:48:33.091887Z","iopub.status.idle":"2023-10-22T08:48:33.117208Z","shell.execute_reply.started":"2023-10-22T08:48:33.091855Z","shell.execute_reply":"2023-10-22T08:48:33.116000Z"},"trusted":true},"execution_count":77,"outputs":[{"execution_count":77,"output_type":"execute_result","data":{"text/plain":"                                              review sentiment  Binry\n0  one reviewer mentioned watching 1 oz episode h...  positive      1\n1  wonderful little production. filming technique...  positive      1\n2  thought wonderful way spend time hot summer we...  positive      1\n3  basically there's family little boy (jake) thi...  negative      0\n4  petter mattei's \"love time money\" visually stu...  positive      1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review</th>\n      <th>sentiment</th>\n      <th>Binry</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>one reviewer mentioned watching 1 oz episode h...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>wonderful little production. filming technique...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>thought wonderful way spend time hot summer we...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>basically there's family little boy (jake) thi...</td>\n      <td>negative</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>petter mattei's \"love time money\" visually stu...</td>\n      <td>positive</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.review[0]","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:48:33.118464Z","iopub.execute_input":"2023-10-22T08:48:33.118865Z","iopub.status.idle":"2023-10-22T08:48:33.128923Z","shell.execute_reply.started":"2023-10-22T08:48:33.118834Z","shell.execute_reply":"2023-10-22T08:48:33.127924Z"},"trusted":true},"execution_count":78,"outputs":[{"execution_count":78,"output_type":"execute_result","data":{"text/plain":"\"one reviewer mentioned watching 1 oz episode hooked. right, exactly happened me.the first thing struck oz brutality unflinching scene violence, set right word go. trust me, show faint hearted timid. show pull punch regard drugs, sex violence. hardcore, classic use word.it called oz nickname given oswald maximum security state penitentary. focus mainly emerald city, experimental section prison cell glass front face inwards, privacy high agenda. em city home many..aryans, muslims, gangstas, latinos, christians, italians, irish more....so scuffles, death stares, dodgy dealing shady agreement never far away.i would say main appeal show due fact go show dare. forget pretty picture painted mainstream audiences, forget charm, forget romance...oz mess around. first episode ever saw struck nasty surreal, say ready it, watched more, developed taste oz, got accustomed high level graphic violence. violence, injustice (crooked guard who'll sold nickel, inmate who'll kill order get away it, well mannered, middle class inmate turned prison bitch due lack street skill prison experience) watching oz, may become comfortable uncomfortable viewing....thats get touch darker side.\""},"metadata":{}}]},{"cell_type":"code","source":"maxlen=1000\nmax_features=5000 \nembed_size=300\n\nX=df.review\nY=df.Binry\n\ntrain_x,test_x,train_y,test_y=train_test_split(X,Y,test_size=0.2,random_state=42,shuffle=True)\n\nval_x=test_x\n#Tokenizing steps- must be remembered\ntokenizer=Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(train_x))\ntrain_x=tokenizer.texts_to_sequences(train_x)\nval_x=tokenizer.texts_to_sequences(val_x)\n\n#Pad the sequence- To allow same length for all vectorized words\ntrain_x=pad_sequences(train_x,maxlen=maxlen)\nval_x=pad_sequences(val_x,maxlen=maxlen)\nval_y=test_y\nprint(\"Padded and Tokenized Training Sequence\".format(),train_x.shape)\nprint(\"Target Values Shape\".format(),train_y.shape)\nprint(\"Padded and Tokenized Training Sequence\".format(),val_x.shape)\nprint(\"Target Values Shape\".format(),val_y.shape)","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:48:33.130271Z","iopub.execute_input":"2023-10-22T08:48:33.130852Z","iopub.status.idle":"2023-10-22T08:48:33.408139Z","shell.execute_reply.started":"2023-10-22T08:48:33.130814Z","shell.execute_reply":"2023-10-22T08:48:33.406886Z"},"trusted":true},"execution_count":79,"outputs":[{"name":"stdout","text":"Padded and Tokenized Training Sequence (800, 1000)\nTarget Values Shape (800,)\nPadded and Tokenized Training Sequence (200, 1000)\nTarget Values Shape (200,)\n","output_type":"stream"}]},{"cell_type":"code","source":"model=Sequential()\nmodel.add(Embedding(max_features,embed_size,input_length=maxlen))\nmodel.add(LSTM(60))\nmodel.add(Dense(16,activation='relu'))\nmodel.add(Dense(1,activation='sigmoid'))\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()\nplot_model(\n    model,\n    to_file=\"simple_model.png\",\n    show_shapes=True,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=96,\n)\nmodel.fit(train_x,train_y,batch_size=128,epochs=3,verbose=2,validation_data=(val_x,val_y))","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:48:33.409538Z","iopub.execute_input":"2023-10-22T08:48:33.409899Z","iopub.status.idle":"2023-10-22T08:49:13.425543Z","shell.execute_reply.started":"2023-10-22T08:48:33.409867Z","shell.execute_reply":"2023-10-22T08:49:13.424761Z"},"trusted":true},"execution_count":80,"outputs":[{"name":"stdout","text":"Model: \"sequential_2\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n embedding_2 (Embedding)     (None, 1000, 300)         1500000   \n                                                                 \n lstm_2 (LSTM)               (None, 60)                86640     \n                                                                 \n dense_4 (Dense)             (None, 16)                976       \n                                                                 \n dense_5 (Dense)             (None, 1)                 17        \n                                                                 \n=================================================================\nTotal params: 1,587,633\nTrainable params: 1,587,633\nNon-trainable params: 0\n_________________________________________________________________\nEpoch 1/3\n7/7 - 16s - loss: 0.6917 - accuracy: 0.5512 - val_loss: 0.6872 - val_accuracy: 0.6200 - 16s/epoch - 2s/step\nEpoch 2/3\n7/7 - 12s - loss: 0.6622 - accuracy: 0.8938 - val_loss: 0.6678 - val_accuracy: 0.6600 - 12s/epoch - 2s/step\nEpoch 3/3\n7/7 - 12s - loss: 0.5777 - accuracy: 0.9500 - val_loss: 0.5852 - val_accuracy: 0.7500 - 12s/epoch - 2s/step\n","output_type":"stream"},{"execution_count":80,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f61f8570730>"},"metadata":{}}]},{"cell_type":"code","source":"train_sample=X\ntokenizer=Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(train_sample))\ntrain_sample=tokenizer.texts_to_sequences(train_sample)\ntrain_sample=pad_sequences(train_sample,maxlen=maxlen)\nword_index = tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:51:14.087831Z","iopub.execute_input":"2023-10-22T08:51:14.088260Z","iopub.status.idle":"2023-10-22T08:51:14.417341Z","shell.execute_reply.started":"2023-10-22T08:51:14.088228Z","shell.execute_reply":"2023-10-22T08:51:14.416283Z"},"trusted":true},"execution_count":82,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nembeddings_index = {}\nf = open('/kaggle/input/glove-global-vectors-for-word-representation/glove.6B.200d.txt','r',encoding='utf-8')\nfor line in tqdm(f):\n    values = line.split(' ')\n    word = values[0]\n    coefs = np.asarray([float(val) for val in values[1:]])\n    embeddings_index[word] = coefs\nf.close()\n\nprint('Found %s word vectors.' % len(embeddings_index))","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:51:48.950327Z","iopub.execute_input":"2023-10-22T08:51:48.950748Z","iopub.status.idle":"2023-10-22T08:52:25.232944Z","shell.execute_reply.started":"2023-10-22T08:51:48.950693Z","shell.execute_reply":"2023-10-22T08:52:25.231859Z"},"trusted":true},"execution_count":84,"outputs":[{"name":"stderr","text":"400000it [00:36, 11028.37it/s]","output_type":"stream"},{"name":"stdout","text":"Found 400000 word vectors.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"embedding_matrix = np.zeros((len(word_index) + 1, 200))\nfor word, i in tqdm(word_index.items()):\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[i] = embedding_vector","metadata":{"execution":{"iopub.status.busy":"2023-10-22T08:52:54.015923Z","iopub.execute_input":"2023-10-22T08:52:54.017179Z","iopub.status.idle":"2023-10-22T08:52:54.121765Z","shell.execute_reply.started":"2023-10-22T08:52:54.017142Z","shell.execute_reply":"2023-10-22T08:52:54.120411Z"},"trusted":true},"execution_count":85,"outputs":[{"name":"stderr","text":"100%|██████████| 18190/18190 [00:00<00:00, 196253.65it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"inp=Input(shape=(maxlen,))\nz=Embedding(len(word_index) + 1,200,weights=[embedding_matrix],trainable=False)(inp)\nz=Bidirectional(LSTM(60,return_sequences='True',dropout=0.3, recurrent_dropout=0.3))(z)\nz=GlobalMaxPool1D()(z)\nz=Dense(16,activation='relu')(z)\nz=Dense(1,activation='sigmoid')(z)\nmodel=Model(inputs=inp,outputs=z)\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()\nplot_model(\n    model,\n    to_file=\"glove_simple_model.png\",\n    show_shapes=True,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=96,\n)\n\nmodel.fit(train_x,train_y,batch_size=128,epochs=3,verbose=2,validation_data=(val_x,val_y))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}